{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47c03acc",
   "metadata": {},
   "source": [
    "## N-gram 언어 모델로 문장 생성\n",
    "\n",
    "네이버에서 오픈소스 제공 nsmc 영화 리뷰 데이터셋을 이용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72937459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk import word_tokenize\n",
    "from nltk import ConditionalFreqDist\n",
    "from nltk.probability import ConditionalProbDist, MLEProbDist\n",
    "import numpy as np\n",
    "import codecs\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae13694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어 처리에 필요한 konlpy 패키지를 설치하기 전에 선행 파일을 설치한다. \n",
    "from konlpy.tag import Okt\n",
    "JAVA_HOME = \"C:\\Program Files\\Java\\jdk1.8.0_202\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf046220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK 패키지를 이용하여 입력 텍스트를 N-gram 형태로 변환한다.\n",
    "sentence = \"나는 매일 아침 아홉시 수업이 있다. 너무 힘들다\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd06d66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Hertaehoon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# NLTK 사용을 위하여 선행 패키지를 설치한다.\n",
    "nltk.download('punkt')\n",
    "\n",
    "# 입력 텍스트를 띄어쓰기 기준으로 토큰화한다.\n",
    "tokens = word_tokenize(sentence) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee6bce0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나는', '매일', '아침', '아홉시', '수업이', '있다', '.', '너무', '힘들다']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baa04130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나/Noun', '는/Josa', '매일/Noun', '아침/Noun', '아홉시/Noun', '수업/Noun', '이/Josa', '있다/Adjective', './Punctuation', '너무/Adverb', '힘들다/Adjective']\n"
     ]
    }
   ],
   "source": [
    "# 한국어의 단어는 띄어쓰기를 기준으로 하지 않기 때문에 konlpy를 이용해 형태소를 기준으로 토큰화한다.\n",
    "tagger = Okt()\n",
    "\n",
    "def tokenize(text):\n",
    "  tokens = ['/'.join(t) for t in tagger.pos(text)]\n",
    "  return tokens\n",
    "\n",
    "tokens = tokenize(sentence)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f412099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = ngrams(tokens, 2)\n",
    "trigram = ngrams(tokens, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cd2bc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram: \n",
      "('나/Noun', '는/Josa')\n",
      "('는/Josa', '매일/Noun')\n",
      "('매일/Noun', '아침/Noun')\n",
      "('아침/Noun', '아홉시/Noun')\n",
      "('아홉시/Noun', '수업/Noun')\n",
      "('수업/Noun', '이/Josa')\n",
      "('이/Josa', '있다/Adjective')\n",
      "('있다/Adjective', './Punctuation')\n",
      "('./Punctuation', '너무/Adverb')\n",
      "('너무/Adverb', '힘들다/Adjective')\n",
      "\n",
      "trigram: \n",
      "('나/Noun', '는/Josa', '매일/Noun')\n",
      "('는/Josa', '매일/Noun', '아침/Noun')\n",
      "('매일/Noun', '아침/Noun', '아홉시/Noun')\n",
      "('아침/Noun', '아홉시/Noun', '수업/Noun')\n",
      "('아홉시/Noun', '수업/Noun', '이/Josa')\n",
      "('수업/Noun', '이/Josa', '있다/Adjective')\n",
      "('이/Josa', '있다/Adjective', './Punctuation')\n",
      "('있다/Adjective', './Punctuation', '너무/Adverb')\n",
      "('./Punctuation', '너무/Adverb', '힘들다/Adjective')\n"
     ]
    }
   ],
   "source": [
    "print(\"bigram: \")\n",
    "for b in bigram:\n",
    "  print(b)\n",
    "\n",
    "print(\"\\ntrigram: \")\n",
    "for t in trigram:\n",
    "  print(t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e6b8602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams with padding: \n",
      "('', '나/Noun')\n",
      "('나/Noun', '는/Josa')\n",
      "('는/Josa', '매일/Noun')\n",
      "('매일/Noun', '아침/Noun')\n",
      "('아침/Noun', '지하철/Noun')\n",
      "('지하철/Noun', '을/Josa')\n",
      "('을/Josa', '탄다/Verb')\n",
      "('탄다/Verb', '')\n"
     ]
    }
   ],
   "source": [
    "bigram = ngrams(tokens, 2, pad_left=True, pad_right=True, left_pad_symbol=\"\", right_pad_symbol=\"\")\n",
    "print(\"bigrams with padding: \")\n",
    "for b in bigram:\n",
    "  print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "072af547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 생성을 위하여 네이버 영화 리뷰 데이터셋을 다운로드한다.\n",
    "!wget -nc -q https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ff54ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋:  [['9976970', '아 더빙.. 진짜 짜증나네요 목소리', '0'], ['3819312', '흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나', '1'], ['10265843', '너무재밓었다그래서보는것을추천한다', '0'], ['9045019', '교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정', '0'], ['6483659', '사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다', '1'], ['5403919', '막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.', '0'], ['7797314', '원작의 긴장감을 제대로 살려내지못했다.', '0'], ['9443947', '별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단 낫겟다 납치.감금만반복반복..이드라마는 가족도없다 연기못하는사람만모엿네', '0'], ['7156791', '액션이 없는데도 재미 있는 몇안되는 영화', '1'], ['5912145', '왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?', '1']]\n",
      "\n",
      "텍스트 데이터: ['아 더빙.. 진짜 짜증나네요 목소리', '흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나', '너무재밓었다그래서보는것을추천한다', '교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정', '사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다']\n",
      "\n",
      "문장 개수:  150000\n"
     ]
    }
   ],
   "source": [
    "# 다운로드 받은 데이터셋을 읽고 인덱스와 라벨을 제외한 텍스트 부분만 가져온다.\n",
    "# codecs 패키지는 대용량 파일을 조금씩 읽을 수 있게 해준다. \n",
    "\n",
    "with codecs.open(\"ratings_train.txt\", encoding='utf-8') as f:\n",
    "  data = [line.split('\\t') for line in f.read().splitlines()] # \\n 제외\n",
    "  data = data[1:] # header 제외\n",
    "print(\"데이터셋: \", data[:10])\n",
    "docs = [row[1] for row in data] # 텍스트 부분만 가져옴\n",
    "print(\"\\n텍스트 데이터:\", docs[:5])\n",
    "print(\"\\n문장 개수: \",len(docs)) # 총 15만개의 문장으로 이루어진 데이터셋임을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d1cb52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 150000/150000 [02:54<00:00, 857.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# 토큰화한 텍스트 데이터의 bigram을 모두 리스트에 추가한다.\n",
    "sentences = []\n",
    "for d in tqdm(docs):\n",
    "  tokens = tokenize(d)\n",
    "  bigram = ngrams(tokens, 2, pad_left=True, pad_right=True, left_pad_symbol=\"\", right_pad_symbol=\"\")\n",
    "  sentences += [t for t in bigram]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af2e5896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', '아/Exclamation'), ('아/Exclamation', '더빙/Noun'), ('더빙/Noun', '../Punctuation'), ('../Punctuation', '진짜/Noun'), ('진짜/Noun', '짜증나네요/Adjective'), ('짜증나네요/Adjective', '목소리/Noun'), ('목소리/Noun', ''), ('', '흠/Noun'), ('흠/Noun', '.../Punctuation'), ('.../Punctuation', '포스터/Noun')]\n"
     ]
    }
   ],
   "source": [
    "print(sentences[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbcb4708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('정말/Noun', 2718), ('이/Noun', 2371), ('진짜/Noun', 2232), ('이/Determiner', 2115), ('영화/Noun', 2069)]\n"
     ]
    }
   ],
   "source": [
    "cfd = ConditionalFreqDist(sentences)\n",
    "print(cfd[\"\"].most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f3621db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 토큰(c) 다음에 가장 많이 등장하는 n개의 단어를 반환하는 함수를 만든다.\n",
    "def most_common(c, n, pos=None):\n",
    "  if pos is None:\n",
    "    return cfd[tokenize(c)[0]].most_common(n)\n",
    "  else:\n",
    "    return cfd[\"/\".join([c, pos])].most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db04c64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('는/Josa', 831), ('의/Josa', 339), ('만/Josa', 213), ('에게/Josa', 148), ('에겐/Josa', 84), ('랑/Josa', 81), ('한테/Josa', 50), ('참/Verb', 45), ('이/Determiner', 44), ('와도/Josa', 43)]\n"
     ]
    }
   ],
   "source": [
    "print(most_common(\"나\", 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4daa9302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어별 등장 빈도를 기반으로 조건부 확률을 추정한다.\n",
    "cpd = ConditionalProbDist(cfd, MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "503a5a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39102658679807606\n"
     ]
    }
   ],
   "source": [
    "# “.” 다음에 “”가 올 확률을 출력한다.\n",
    "print(cpd[tokenize(\".\")[0]].prob(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74768da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰 c 다음에 토큰 w가 bigram으로 함께 등장할 확률을 구한다.\n",
    "def bigram_prob(c, w):\n",
    "  context = tokenize(c)[0]\n",
    "  word = tokenize(w)[0]\n",
    "  return cpd[context].prob(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5334ec46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4010748656417948\n"
     ]
    }
   ],
   "source": [
    "print(bigram_prob(\"이\", \"영화\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5b75ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00015767585785521414\n"
     ]
    }
   ],
   "source": [
    "print(bigram_prob(\"영화\", \"이\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b43fd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조건부 확률을 알게 되면 가장 확률이 높은 토큰열을 토대로 문장을 생성할 수 있다.\n",
    "def generate_sentence(seed=None, debug=False):\n",
    "  if seed is not None:\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "  c = \"\"\n",
    "  sentence = []\n",
    "  while True:\n",
    "    if c not in cpd:\n",
    "      break\n",
    "    w = cpd[c].generate()\n",
    "\n",
    "    if w == \"\":\n",
    "      break\n",
    "    \n",
    "    word = w.split(\"/\")[0]\n",
    "    pos = w.split(\"/\")[1]\n",
    "\n",
    "    # 조사, 어미 등을 제외하고 각 토큰은 띄어쓰기로 구분하여 생성한다.\n",
    "    if c == \"\":\n",
    "      sentence.append(word.title())\n",
    "    elif c in [\"`\", \"\\\"\",\"'\",\"(\"]:\n",
    "      sentence.append(word)\n",
    "    elif word in [\"'\", \".\", \",\", \")\", \":\", \";\", \"?\"]:\n",
    "      sentence.append(word)\n",
    "    elif pos in [\"Josa\", \"Punctuation\", \"Suffix\"]:\n",
    "        sentence.append(word)\n",
    "    elif w in [\"임/Noun\", \"것/Noun\", \"는걸/Noun\", \"릴때/Noun\",\n",
    "                \"되다/Verb\", \"이다/Verb\", \"하다/Verb\", \"이다/Adjective\"]:\n",
    "        sentence.append(word)\n",
    "    else:\n",
    "        sentence.append(\" \" + word)\n",
    "    c = w\n",
    "\n",
    "    if debug:\n",
    "      print(w)\n",
    "\n",
    "  return \"\".join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d97aec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "도리까지 본 영화 너무... 뭔가.. 최고네요. 하지만.. 눈물 낫다는건 또 영화에 들지 않는다. 근데 뭐야 어떻게 그렇게 착했던 윤재랑은 에바 그린 드레스 소리 듣는거임\"\"\" 에리 욧의 미모로 합성 한 가수 노래와 흥행 놓친 영화다. 사투리 연기 하나 없는 ‘ 스피드 감 넘치는 스릴 넘치는 연기를 이해 되지 못 하시는 분보다 훨 재밌구만 평점을 망처 놓은 듯하다. 영화 보는이로 하여금 불편함을 느꼇을듯\n"
     ]
    }
   ],
   "source": [
    "print(generate_sentence(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "175aa405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "도리/Noun\n",
      "까지/Josa\n",
      "본/Verb\n",
      "영화/Noun\n",
      "너무/Adverb\n",
      ".../Punctuation\n",
      "뭔가/Noun\n",
      "../Punctuation\n",
      "최고/Noun\n",
      "네/Suffix\n",
      "요/Josa\n",
      "./Punctuation\n",
      "하지만/Conjunction\n",
      "../Punctuation\n",
      "눈물/Noun\n",
      "낫다는건/Verb\n",
      "또/Noun\n",
      "영화/Noun\n",
      "에/Josa\n",
      "들지/Verb\n",
      "않는다/Verb\n",
      "./Punctuation\n",
      "근데/Adverb\n",
      "뭐/Noun\n",
      "야/Josa\n",
      "어떻게/Adjective\n",
      "그렇게/Adverb\n",
      "착했던/Adjective\n",
      "윤재/Noun\n",
      "랑은/Josa\n",
      "에바/Noun\n",
      "그린/Noun\n",
      "드레스/Noun\n",
      "소리/Noun\n",
      "듣는거/Verb\n",
      "임/Noun\n",
      "\"\"\"/Punctuation\n",
      "에리/Noun\n",
      "욧의/Noun\n",
      "미모/Noun\n",
      "로/Josa\n",
      "합성/Noun\n",
      "한/Determiner\n",
      "가수/Noun\n",
      "노래/Noun\n",
      "와/Josa\n",
      "흥행/Noun\n",
      "놓친/Verb\n",
      "영화/Noun\n",
      "다/Josa\n",
      "./Punctuation\n",
      "사투리/Noun\n",
      "연기/Noun\n",
      "하나/Noun\n",
      "없는/Adjective\n",
      "‘/Foreign\n",
      "스피드/Noun\n",
      "감/Noun\n",
      "넘치는/Adjective\n",
      "스릴/Noun\n",
      "넘치는/Adjective\n",
      "연기/Noun\n",
      "를/Josa\n",
      "이해/Noun\n",
      "되지/Verb\n",
      "못/VerbPrefix\n",
      "하시는/Verb\n",
      "분/Noun\n",
      "보다/Josa\n",
      "훨/Noun\n",
      "재밌구만/Adjective\n",
      "평점/Noun\n",
      "을/Josa\n",
      "망처/Noun\n",
      "놓은/Verb\n",
      "듯/Noun\n",
      "하다/Verb\n",
      "./Punctuation\n",
      "영화/Noun\n",
      "보는이로/Verb\n",
      "하여금/Adverb\n",
      "불편함을/Adjective\n",
      "느꼇을듯/Noun\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'도리까지 본 영화 너무... 뭔가.. 최고네요. 하지만.. 눈물 낫다는건 또 영화에 들지 않는다. 근데 뭐야 어떻게 그렇게 착했던 윤재랑은 에바 그린 드레스 소리 듣는거임\"\"\" 에리 욧의 미모로 합성 한 가수 노래와 흥행 놓친 영화다. 사투리 연기 하나 없는 ‘ 스피드 감 넘치는 스릴 넘치는 연기를 이해 되지 못 하시는 분보다 훨 재밌구만 평점을 망처 놓은 듯하다. 영화 보는이로 하여금 불편함을 느꼇을듯'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence(2, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ec0d28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
